"""add ai models

Revision ID: 02065227fdc1
Revises: 06f470a082c1
Create Date: 2025-04-15 16:55:37.280095

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '02065227fdc1'
down_revision: Union[str, None] = '06f470a082c1'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('ai_dialogs',
    sa.Column('id', sa.String(), nullable=False),
    sa.Column('chat_id', sa.String(), nullable=False),
    sa.Column('user_id', sa.String(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), nullable=False),
    sa.ForeignKeyConstraint(['chat_id'], ['telegram_messenger_chats.id'], ),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('ai_requests',
    sa.Column('id', sa.String(), nullable=False),
    sa.Column('dialog_id', sa.String(), nullable=False),
    sa.Column('user_id', sa.String(), nullable=False),
    sa.Column('request_text', sa.String(), nullable=False),
    sa.Column('response_text', sa.String(), nullable=False),
    sa.Column('model', sa.Enum('GPT_4_1', 'GPT_4_1_MINI', 'GPT_4_1_NANO', 'CLAUDE_3_7_SONNET', 'CLAUDE_3_5_HAIKU', name='airequestmodel'), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), nullable=False),
    sa.ForeignKeyConstraint(['dialog_id'], ['ai_dialogs.id'], ),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.add_column(sa.Column('preferred_ai_model', sa.Enum('GPT_4_1', 'GPT_4_1_MINI', 'GPT_4_1_NANO', 'CLAUDE_3_7_SONNET', 'CLAUDE_3_5_HAIKU', name='airequestmodel'), nullable=True))
        batch_op.add_column(sa.Column('preferred_message_context_size', sa.Integer(), nullable=True))

    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.drop_column('preferred_message_context_size')
        batch_op.drop_column('preferred_ai_model')

    op.drop_table('ai_requests')
    op.drop_table('ai_dialogs')
    # ### end Alembic commands ###
